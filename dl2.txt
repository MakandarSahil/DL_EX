import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Step 3: Preprocess the Data
# Flatten 28x28 images into 784-dimensional vectors
x_train = x_train.reshape((60000, 28 * 28)).astype('float32') / 255
x_test = x_test.reshape((10000, 28 * 28)).astype('float32') / 255

# Convert labels to one-hot encoded vectors
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Step 4: Build the Model (Shallow Neural Network)
model = models.Sequential([
layers.Dense(128, activation='relu', input_shape=(784,)), # hidden layer
layers.Dense(10, activation='softmax') # output layer
])

# Step 5: Compile the Model
model.compile(
optimizer='adam',
loss='categorical_crossentropy',
metrics=['accuracy']
)
# Step 6: Train the Model
model.fit(x_train, y_train, epochs=5, batch_size=128, verbose=1)

# Step 7: Evaluate on Test Data
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f'\n Test accuracy: {test_acc:.4f}')
