# Step 1: Import Libraries
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Step 2: Load CIFAR-10 Dataset
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Step 2.2: Normalize input images
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Step 2.3: One-hot encode labels
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)
def build_cnn_model():
model = Sequential([
Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),
MaxPooling2D((2,2)),
Conv2D(64, (3,3), activation='relu'),
MaxPooling2D((2,2)),
Flatten(),
Dense(128, activation='relu'),
Dropout(0.5),
Dense(10, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
return model

model = build_cnn_model()
model.summary()

# Step 5: Train the Model
history = model.fit(
x_train, y_train,
epochs=5,
batch_size=64,
validation_split=0.2,
verbose=1
)

# Step 6: Plot Training and Validation Accuracy & Loss
plt.figure(figsize=(12,5))
<matplotlib.legend.Legend at 0x7abc4ebde720>
# Accuracy
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training vs Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()


# Loss
plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training vs Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()


import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
import keras_tuner as kt

# Load MNIST
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(-1, 28*28).astype("float32") / 255
x_test = x_test.reshape(-1, 28*28).astype("float32") / 255
# Function to build model, hyperparameters are passed by Keras Tuner
def build_model(hp):
model = models.Sequential()

# Tune hidden units in first layer
model.add(layers.Dense(
units=hp.Int('units1', min_value=64, max_value=256, step=64),
activation='relu',
input_shape=(784,)
))

# Function to build model, hyperparameters are passed by Keras Tuner
def build_model(hp):
model = models.Sequential()

# Tune hidden units in first layer
model.add(layers.Dense(
units=hp.Int('units1', min_value=64, max_value=256, step=64),
activation='relu',
input_shape=(784,)
))

# Tune hidden units in second layer
model.add(layers.Dense(
units=hp.Int('units2', min_value=32, max_value=128, step=32),
activation='relu'
))

# Output layer
model.add(layers.Dense(10, activation='softmax'))
# Tune learning rate
lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 5e-4])
model.compile(
optimizer=tf.keras.optimizers.Adam(learning_rate=lr),
loss='sparse_categorical_crossentropy',
metrics=['accuracy']
)
return model

# Initialize tuner
tuner = kt.RandomSearch(
build_model,
objective='val_accuracy',
max_trials=5, # number of hyperparameter combinations to try
executions_per_trial=1,
directory='my_dir',
project_name='mnist_tuning'
)

# Run search
tuner.search(x_train, y_train, epochs=5, validation_split=0.1)


# Get the best model and hyperparameters
best_model = tuner.get_best_models(num_models=1)[0]
best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]
print(" Best Hyperparameters:")
print(f"units1: {best_hp.get('units1')}")
print(f"units2: {best_hp.get('units2')}")
print(f"learning_rate: {best_hp.get('learning_rate')}")


# Evaluate on test data
test_loss, test_acc = best_model.evaluate(x_test, y_test)
print(f"\n Test accuracy: {test_acc:.4f}")
